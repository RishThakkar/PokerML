{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2434a683",
   "metadata": {},
   "source": [
    "# PokerML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcefa6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af043357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c0167",
   "metadata": {},
   "source": [
    "Make sure that you have Vivado suite in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c375ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44f731",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86514582",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "DATA_NPY_DIR = DATA_DIR + '/npy/Suits_npy/'\n",
    "\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "QKERAS_TRAIN = False ## I did not debug yet the issue with the QKeras saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0e75c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240b2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = np.load(DATA_NPY_DIR + 'X_train_val.npy')\n",
    "X_test = np.load(DATA_NPY_DIR + 'X_test.npy')\n",
    "y_train_val = np.load(DATA_NPY_DIR + 'y_train_val.npy')\n",
    "y_test = np.load(DATA_NPY_DIR + 'y_test.npy')\n",
    "classes = np.load(DATA_NPY_DIR + 'classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ed16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation set: 7987\n",
      "Test set:                 1997\n",
      "Classes:                  4\n"
     ]
    }
   ],
   "source": [
    "print('Train and validation set:', X_train_val.shape[0])\n",
    "print('Test set:                ', X_test.shape[0])\n",
    "print('Classes:                 ', classes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c78db2",
   "metadata": {},
   "source": [
    "## Train QKeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6a2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "from qkeras import QDense, QActivation, QConv2D\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "\n",
    "# # ENABLE THIS IF YOU USE PRUNING\n",
    "# from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "# from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17aee1dd",
   "metadata": {},
   "source": [
    "CHECKPOINT_FILENAME = MODELS_DIR + 'qkeras/model.h5'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv1'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu1'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool1'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "model.add(QDense(NUM_CLASSES,\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 activation='softmax',\n",
    "                 name='output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bebd4f41",
   "metadata": {},
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "filters_per_conv_layer = [16, 16, 24]\n",
    "neurons_per_dense_layer = [42, 64]\n",
    "\n",
    "x = x_in = Input(shape=input_shape)\n",
    "\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding fused QConv+BN block {} with N={} filters').format(i, f))\n",
    "    x = QConv2DBatchnorm(\n",
    "        int(f),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        bias_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        use_bias=True,\n",
    "        name='fused_convbn_{}'.format(i),\n",
    "    )(x)\n",
    "    x = QActivation('quantized_relu(6)', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_{}'.format(i))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i, n in enumerate(neurons_per_dense_layer):\n",
    "    print(('Adding QDense block {} with N={} neurons').format(i, n))\n",
    "    x = QDense(\n",
    "        n,\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        name='dense_%i' % i,\n",
    "        use_bias=False,\n",
    "    )(x)\n",
    "    x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "    x = QActivation('quantized_relu(6)', name='dense_act_%i' % i)(x)\n",
    "x = Dense(int(n_classes), name='output_dense')(x)\n",
    "x_out = Activation('softmax', name='output_softmax')(x)\n",
    "qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29dcdfd4",
   "metadata": {},
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "# Define the filters and neurons per layer\n",
    "filters_per_conv_layer = [4, 4]\n",
    "neurons_per_dense_layer = [NUM_CLASSES]\n",
    "\n",
    "# Define input shape\n",
    "x_in = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "# Initialize input tensor\n",
    "x = x_in\n",
    "\n",
    "# Add convolutional layers\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding QConv2D block {} with N={} filters').format(i, f))\n",
    "    x = QConv2D(\n",
    "        f,\n",
    "        kernel_size=(3, 3),\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        bias_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        name='conv_%i' % i,\n",
    "    )(x)\n",
    "    x = QActivation('quantized_relu(6)', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_%i' % i)(x)\n",
    "\n",
    "# Flatten the output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# # Add dense layers\n",
    "# for i, n in enumerate(neurons_per_dense_layer):\n",
    "#     print(('Adding QDense block {} with N={} neurons').format(i, n))\n",
    "#     x = QDense(\n",
    "#         n,\n",
    "#         kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "#         kernel_initializer='lecun_uniform',\n",
    "#         kernel_regularizer=l1(0.0001),\n",
    "#         name='dense_%i' % i,\n",
    "#         use_bias=False,\n",
    "#     )(x)\n",
    "#     x = BatchNormalization(name='bn_dense_%i' % i)(x)\n",
    "#     x = QActivation('quantized_relu(6)', name='dense_act_%i' % i)(x)\n",
    "\n",
    "# Define output layer\n",
    "x_out = QDense(\n",
    "    NUM_CLASSES,\n",
    "    kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "    kernel_initializer='lecun_uniform',\n",
    "    kernel_regularizer=l1(0.0001),\n",
    "    activation='softmax',\n",
    "    name='output',\n",
    ")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0baa3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/esp2024/rht2122/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (QConv2D)             (None, 62, 62, 4)         112       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 62, 62, 4)         0         \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 31, 31, 4)         0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 29, 29, 4)         148       \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 29, 29, 4)         0         \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 14, 14, 4)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " output (QDense)             (None, 4)                 3140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,400\n",
      "Trainable params: 3,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_FILENAME = MODELS_DIR + 'qkeras/suits_model.h5'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv1'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu1'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool1'))\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv2'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu2'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool2'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "# model.add(QDense(32,\n",
    "#                  kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "#                  bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "#                  kernel_initializer='lecun_uniform',\n",
    "#                  kernel_regularizer=l1(0.0001),\n",
    "#                  name='dense1'))\n",
    "\n",
    "# model.add(QActivation(activation=quantized_relu(6),\n",
    "#                       name='relu3'))\n",
    "\n",
    "model.add(QDense(NUM_CLASSES,\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 activation='softmax',\n",
    "                 name='output'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# # adding pruning \n",
    "# pruning_params = {\n",
    "#     'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "#         initial_sparsity=0.50,\n",
    "#         final_sparsity=0.80,\n",
    "#         begin_step=200,\n",
    "#         end_step=1000)\n",
    "# }\n",
    "# model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19cb8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if QKERAS_TRAIN:\n",
    "    from qkeras.utils import model_save_quantized_weights\n",
    "\n",
    "    # Using learning rate with exponential decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.001,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    adam = Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    #adam = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "    # A few other callbacks. These should not give warnings on deprecated features.\n",
    "    callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                CHECKPOINT_FILENAME,\n",
    "                monitor='val_loss',\n",
    "                verbose=0,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                save_freq='epoch')\n",
    "       #,\n",
    "       #pruning_callbacks.UpdatePruningStep()\n",
    "       #,#ReduceLROnPlateau(patience=75, min_delta=1**-6), \n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        batch_size=128,\n",
    "        epochs=30,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "# # Strip the model of pruning information\n",
    "#     model = strip_pruning(model)\n",
    "#    model.save(CHECKPOINT_FILENAME)\n",
    "\n",
    "    # Use this instead if you use the callbacks\n",
    "    history_file = CHECKPOINT_FILENAME.replace('.h5', '-history.pkl')\n",
    "    with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    print(f'Saving history to: {history_file}')\n",
    "    print(f'Saved checkpoint to: {CHECKPOINT_FILENAME}')\n",
    "\n",
    "\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model(CHECKPOINT_FILENAME, custom_objects=co, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0644b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "if QKERAS_TRAIN:\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Test')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Test')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12dd892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 15ms/step\n",
      "QKeras accuracy: 95.693540%\n"
     ]
    }
   ],
   "source": [
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "\n",
    "print(\"QKeras accuracy: {:.6f}%\".format(100.*accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ab571",
   "metadata": {},
   "source": [
    "Pre trained model sul have accuracy = 98.030708%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4935b80",
   "metadata": {},
   "source": [
    "## QKeras to hls4ml (Quantization Aware Training)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edea044",
   "metadata": {},
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "# Then the QKeras model\n",
    "hls_config_q = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config_q['Model']['ReuseFactor'] = 512\n",
    "hls_config_q['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_q['LayerName']['output']['Strategy'] = 'Stable'\n",
    "hls_config_q['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_q['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "plotting.print_dict(hls_config_q)\n",
    "\n",
    "cfg_q = hls4ml.converters.create_config(backend='VivadoAccelerator')\n",
    "cfg_q['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg_q['HLSConfig'] = hls_config_q\n",
    "cfg_q['KerasModel'] = model\n",
    "cfg_q['OutputDir'] = 'projects/qat_hls4ml_prj_rank'\n",
    "# cfg_q['XilinxPart'] = 'xczu5ev-sfvc784-2LV-e'\n",
    "\n",
    "hls_model_q = hls4ml.converters.keras_to_hls(cfg_q)\n",
    "hls_model_q.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5af2572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1_input, layer type: InputLayer, input shapes: [[None, 64, 64, 3]], output shape: [None, 64, 64, 3]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 64, 64, 3]], output shape: [None, 62, 62, 4]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 62, 62, 4]], output shape: [None, 62, 62, 4]\n",
      "Layer name: maxpool1, layer type: MaxPooling2D, input shapes: [[None, 62, 62, 4]], output shape: [None, 31, 31, 4]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 31, 31, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 29, 29, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: maxpool2, layer type: MaxPooling2D, input shapes: [[None, 29, 29, 4]], output shape: [None, 14, 14, 4]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 14, 14, 4]], output shape: [None, 784]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 4]\n",
      "Model\n",
      "  Precision:         ap_fixed<32,16>\n",
      "  ReuseFactor:       256\n",
      "  Strategy:          Resource\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  conv1_input\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  conv1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  conv1_linear\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  relu1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  maxpool1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  conv2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  conv2_linear\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  relu2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  maxpool2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  flatten\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  output\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "  output_softmax\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     256\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1_input, layer type: InputLayer, input shapes: [[None, 64, 64, 3]], output shape: [None, 64, 64, 3]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 64, 64, 3]], output shape: [None, 62, 62, 4]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 62, 62, 4]], output shape: [None, 62, 62, 4]\n",
      "Layer name: maxpool1, layer type: MaxPooling2D, input shapes: [[None, 62, 62, 4]], output shape: [None, 31, 31, 4]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 31, 31, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 29, 29, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: maxpool2, layer type: MaxPooling2D, input shapes: [[None, 29, 29, 4]], output shape: [None, 14, 14, 4]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 14, 14, 4]], output shape: [None, 784]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 4]\n",
      "Creating HLS model\n",
      "WARNING: Strategy for layer conv1_input set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv1_linear set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer relu1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer maxpool1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2_linear set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer relu2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer maxpool2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer flatten set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer output set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer output_softmax set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n",
      "WARNING: Invalid ReuseFactor=256 in layer \"conv1\".Using ReuseFactor=108 instead. Valid ReuseFactor(s): 1,3,9,27,54,108.\n",
      "WARNING: Invalid ReuseFactor=256 in layer \"conv2\".Using ReuseFactor=144 instead. Valid ReuseFactor(s): 1,2,3,4,6,9,12,18,36,72,144.\n",
      "WARNING: Invalid ReuseFactor=256 in layer \"output\".Using ReuseFactor=196 instead. Valid ReuseFactor(s): 1,2,4,7,8,14,16,28,49,56,98,112,196,392,784,1568,3136.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esp2024/rht2122/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "# First, the baseline model\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<32,16>'\n",
    "hls_config['Model']['ReuseFactor'] = 256\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "\n",
    "# Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource'\n",
    "# or increase the reuse factor individually for large layers.\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 256\n",
    "    hls_config['LayerName'][Layer]['Trace'] = True\n",
    "\n",
    "# hls_config['LayerName']['output']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config)\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='VivadoAccelerator')\n",
    "cfg['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg['HLSConfig'] = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = 'projects/qat_hls4ml_prj_Suits'\n",
    "#cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69780387",
   "metadata": {},
   "source": [
    "# DISABLE THIS CELL\n",
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['LayerName']['output']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['output']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "config['Model']['ReuseFactor'] = 256\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='projects/qat_hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3a957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade5610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1997, 64, 64, 3)\n",
      "(10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# IF PREDICTION TAKE TOO MUCH PLEASE\n",
    "# REDUCE THE NUMBER OF INPUTS\n",
    "print(X_test.shape)\n",
    "print(X_test[:10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b8aac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8602e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy quantized: 0.956935%\n",
      "Accuracy hls4ml:    0.955433%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#print(\"Accuracy baseline:  {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"Accuracy quantized: {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
    "print(\"Accuracy hls4ml:    {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2f77a",
   "metadata": {},
   "source": [
    "```\n",
    "With pretrained model you should expect:\n",
    "Accuracy quantized: 0.980307%\n",
    "Accuracy hls4ml:    0.979973%\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9936d809",
   "metadata": {},
   "source": [
    "# THIS AND THE FOLLOWING CELL CAN BE USED TO TUNE THE BITWIDTH OF THE LAYERS\n",
    "# THEY TAKE A LOT OF TIME TO RUN SO FOR THE TIME BEING I DISABLE THEM\n",
    "# IF YOU WANT TO MAKE accuracy hls4 == accuracy qkeras WE WILL USE IT\n",
    "_, hls_trace = hls_model.trace(np.ascontiguousarray(X_test)) \n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test) \n",
    "\n",
    "print(f'HLS Keys: {hls_trace.keys()}')\n",
    "print(f'Keras Keys: {keras_trace.keys()}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5360660",
   "metadata": {},
   "source": [
    "layers = ['conv1', 'relu1', 'maxpool1', 'conv2', 'relu2', 'maxpool2', 'dense1', 'relu3', 'output_softmax']\n",
    "\n",
    "for idx, layer in enumerate(layers):\n",
    "    keras_layer, hls_layer = keras_trace[layer], hls_trace[layer]\n",
    "    try:\n",
    "        diff = np.average(np.abs(keras_layer - hls_layer ))\n",
    "        print(f'{layer}', '\\t\\t', diff)\n",
    "        \n",
    "        plt.figure(figsize=(7, 5))\n",
    "\n",
    "        plt.scatter(hls_layer.flatten(), keras_layer.flatten())\n",
    "        min_x = min(keras_layer.min(), hls_layer.min())\n",
    "        max_x = min(keras_layer.max(), hls_layer.max())\n",
    "\n",
    "        onnx_min, onnx_max = keras_layer.flatten().min(), keras_layer.flatten().max()\n",
    "        hls_min, hls_max = hls_layer.flatten().min(), hls_layer.flatten().max()\n",
    "        \n",
    "        print(f'hls/keras min: {hls_min}/{onnx_min}')\n",
    "        print(f'hls/keras max: {hls_max}/{onnx_max}')\n",
    "        \n",
    "        plt.plot([min_x, max_x], [min_x, max_x], c='red')\n",
    "        plt.axhline(min_x, c='red')\n",
    "        plt.axhline(max_x, c='red')\n",
    "\n",
    "        plt.title(f'(hls) {layer} -- (keras) {layer}')\n",
    "        plt.xlabel(f'hls4ml - [{hls_min:.3f},  {hls_max:.3f}]')\n",
    "        plt.ylabel(f'keras - [{onnx_min:.3f},  {onnx_max:.3f}]')\n",
    "        plt.yscale('linear')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7717b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using seaborn's heatmap.\n",
    "    \n",
    "    Args:\n",
    "        cm (array, shape = [n, n]): Confusion matrix\n",
    "        class_names (array, shape = [n]): Array of class names\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "y_qkeras_ = np.argmax(y_qkeras, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_, y_qkeras_)\n",
    "\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8a152df",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "\n",
    "#hls_model_q.build(csim=False, synth=False, vsynth=True, cosim = False, bitfile = True)\n",
    "hls_model_q.build(csim=False, synth=True, vsynth=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdb6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /opt/xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/opt/xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'rht2122' on host 'socp06-ubuntu.c.psyched-span-141520.internal' (Linux_x86_64 version 5.4.0-1106-gcp) on Wed Apr 10 15:10:19 UTC 2024\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Suits'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Suits/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_axi.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Suits/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xczu5ev-sfvc784-2LV-e'\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 20.\n",
      "INFO: [XFORM 203-1172] Optimizing floating point zeros and discarding its signedness.\n",
      "INFO: [XFORM 203-1172] Optimizing floating point zeros and discarding its signedness.\n",
      "INFO: [XFORM 203-1173] Reordering floating point operations aggressively.\n",
      "INFO: [XFORM 203-1176] Optimizing floating point comparison without checking NaN.\n",
      "INFO: [XFORM 203-102] Do not partition external global variables.\n",
      "INFO: [XFORM 203-102] Do not partition I/O variables.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-102] Enabled automatic array partitioning for throughput optimization.\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -optimization_level' configuration: config_export -vivado_optimization_level=2\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -target' configuration: config_export -vivado_optimization_level=2\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -target' configuration: set_clock_uncertainty default\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "WARNING: [HLS 200-40] Resetting target device to 'xc7z020-clg400-1'\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:37:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:37:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:49:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:49:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:62:71\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:62:76\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 6 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_axi.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:17:2\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:29:5\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 2 issue(s) in file firmware/myproject_axi.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:50 ; elapsed = 00:00:53 . Memory (MB): peak = 972.277 ; gain = 539.074 ; free physical = 11690 ; free virtual = 32565\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:50 ; elapsed = 00:00:53 . Memory (MB): peak = 972.277 ; gain = 539.074 ; free physical = 11690 ; free virtual = 32565\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'void nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:136) in function 'void nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'void nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:136) in function 'void nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[].1' into 'myproject_axi' (firmware/myproject_axi.cpp:21).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:158->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:33).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:305).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:305).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:244).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:60).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:44).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:51).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:51).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:54).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:54).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, config5>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:204).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:247).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:188->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:158->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, config9>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:204).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:247).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:188->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:21).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:54 ; elapsed = 00:00:58 . Memory (MB): peak = 974.383 ; gain = 541.180 ; free physical = 11659 ; free virtual = 32534\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:209) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:224) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:232) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:235) automatically.\n",
      "WARNING: [SYNCHK 200-23] firmware/myproject_axi.cpp:33: variable-indexed range selection may cause suboptimal QoR.\n",
      "INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:56 ; elapsed = 00:00:59 . Memory (MB): peak = 974.383 ; gain = 541.180 ; free physical = 11633 ; free virtual = 32509\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'data.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:1) on argument 'conv1_input.V.data.V' (firmware/myproject.cpp:7). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:98) on argument 'layer12_out.V.data.V' (firmware/myproject.cpp:8). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'out.data' (firmware/myproject_axi.cpp:3).\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'in.data' (firmware/myproject_axi.cpp:3).\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_pack.data.V' (firmware/nnet_utils/nnet_activation_stream.h:237) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:45) into a 24-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:45) into a 24-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:184) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:184) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:55) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'ctype.data.V' (firmware/myproject_axi.cpp:18) into a 48-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:282) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:282) into a 64-bit variable.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:195) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:195) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:193:47).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:41) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:41) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:243) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:243) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DataPrepare' (firmware/nnet_utils/nnet_dense_stream.h:36) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:194:62).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:194:62).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) because its parent loop or function is pipelined.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxArrayPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:201) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/nnet_activation_stream.h:213) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/nnet_activation_stream.h:222) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxInvPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:241) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:49) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' completely with a factor of 4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:49) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:198) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:198) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:42) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:58) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:303) in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:108) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:156) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:303) in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:108) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:156) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [XFORM 203-102] Partitioning array 'd_xi_xmax.V' (firmware/nnet_utils/nnet_activation_stream.h:212) automatically.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w6.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w2.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w6.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w2.V' : incorrect reshape factor 1.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w11.V'  in dimension 1 with a block factor of 16.\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.3' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.2' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.1' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer11_out.V.data.V' (firmware/myproject.cpp:60) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'out_local.V.data.V' (firmware/myproject_axi.cpp:12) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer6_out.V.data.V' (firmware/myproject.cpp:47) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer8_out.V.data.V' (firmware/myproject.cpp:51) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer2_out.V.data.V' (firmware/myproject.cpp:35) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer4_out.V.data.V' (firmware/myproject.cpp:39) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer9_out.V.data.V' (firmware/myproject.cpp:55) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer5_out.V.data.V' (firmware/myproject.cpp:43) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'in_local.V.data.V' (firmware/myproject_axi.cpp:11) .\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_array.V' (firmware/nnet_utils/nnet_activation_stream.h:193) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'exp_res.V' (firmware/nnet_utils/nnet_activation_stream.h:219) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.3'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.2'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_stream.h:44:39), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res.V' (firmware/nnet_utils/nnet_dense_stream.h:32) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b11.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.1'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.V' (firmware/nnet_utils/nnet_conv_stream.h:279) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b6.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:104) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.V' (firmware/nnet_utils/nnet_conv_stream.h:279) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:104) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer11_out.V.data.V' (firmware/myproject.cpp:60) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'out_local.V.data.V' (firmware/myproject_axi.cpp:12) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V.data.V' (firmware/myproject.cpp:47) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer8_out.V.data.V' (firmware/myproject.cpp:51) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer2_out.V.data.V' (firmware/myproject.cpp:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer4_out.V.data.V' (firmware/myproject.cpp:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer9_out.V.data.V' (firmware/myproject.cpp:55) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer5_out.V.data.V' (firmware/myproject.cpp:43) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'in_local.V.data.V' (firmware/myproject_axi.cpp:11) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_resource.h:56:17), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'kernel_data.V.1'  accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_resource.h:139:17), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:209) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:224) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:232) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:235) automatically.\n",
      "INFO: [XFORM 203-721] Changing loop 'Loop_1_proc' (firmware/myproject_axi.cpp:17) to a process function for dataflow in function 'myproject_axi'.\n",
      "INFO: [XFORM 203-721] Changing loop 'Loop_2_proc' (firmware/myproject_axi.cpp:31) to a process function for dataflow in function 'myproject_axi'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject', detected/extracted 8 process function(s): \n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'\n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'\n",
      "\t 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>'\n",
      "\t 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject_axi', detected/extracted 4 process function(s): \n",
      "\t 'Loop_1_proc290'\n",
      "\t 'myproject'\n",
      "\t 'Block_myproject_axi_.exit44_proc'\n",
      "\t 'Loop_2_proc'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_activation_stream.h:248:1) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>'... converting 21 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:41:61) to (firmware/nnet_utils/nnet_activation_stream.h:41:55) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>'... converting 13 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:41:61) to (firmware/nnet_utils/nnet_activation_stream.h:41:55) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>'... converting 13 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:43:16) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:32:90) to (firmware/myproject_axi.cpp:31:49) in function 'Loop_2_proc'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:22:25) to (firmware/myproject_axi.cpp:20:41) in function 'Loop_1_proc290'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.27i16P.i5' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.36i16P.i6' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_activation_stream.h:232) automatically.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)...3 expression(s) balanced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:23:17)...32 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)...3 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:49 ; elapsed = 00:01:53 . Memory (MB): peak = 1164.277 ; gain = 731.074 ; free physical = 11414 ; free virtual = 32290\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:241:66) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:241:66) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:79:66) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:79:66) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>'.\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' to 'softmax_stable<array,array<ap_fixed<16,6,5,3,0>,4u>,softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:43:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, softmax_config12>' to 'softmax<array,array<ap_fixed<16,6,5,3,0>,4u>,softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:362:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:226:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' to 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:226:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' to 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:41:55)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' to 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:41:55)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' to 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config9>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' to 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config5>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' to 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:13)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:1:17)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:1:17)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config11>' to 'dense<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config11>' (firmware/nnet_utils/nnet_dense_stream.h:36:39)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'conv_2d_cl<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:79:27)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' to 'conv_2d_cl<array<ap_fixed,3u>,array<ap_fixed<16,6,5,3,0>,4u>,config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:79:27)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config6>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' to 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config2>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:129) in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:129) in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:02:36 ; elapsed = 00:02:41 . Memory (MB): peak = 1338.879 ; gain = 905.676 ; free physical = 4946 ; free virtual = 25822\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject_axi' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' to 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config2>' to 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array<ap_fixed,3u>,array<ap_fixed<16,6,5,3,0>,4u>,config2>' to 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config4>' to 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config5>' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' to 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config6>' to 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config6>' to 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config8>' to 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config9>' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' to 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config11>' to 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax_stable<array,array<ap_fixed<16,6,5,3,0>,4u>,softmax_config12>' to 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_4u_softmax_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax<array,array<ap_fixed<16,6,5,3,0>,4u>,softmax_config12>' to 'softmax_array_array_ap_fixed_16_6_5_3_0_4u_softmax_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'Block_myproject_axi_.exit44_proc' to 'Block_myproject_axi_exit44_proc'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Loop_1_proc290' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 162.57 seconds; current allocated memory: 518.202 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 518.728 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 518.986 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 519.222 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s' consists of the following:\n",
      "\t'phi' operation ('acc_0_V_020', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [42]  (0 ns)\n",
      "\t'mux' operation ('tmp', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [149]  (1.96 ns)\n",
      "\t'add' operation ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [150]  (2.55 ns)\n",
      "\tmultiplexor before 'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [166]  (1.77 ns)\n",
      "\t'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [166]  (0 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 519.835 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 520.697 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s' consists of the following:\n",
      "\t'call' operation ('tmp', firmware/nnet_utils/nnet_conv_stream.h:297) to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' [147]  (6.28 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 521.142 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 521.657 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 521.803 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 522.034 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 522.429 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.45 seconds; current allocated memory: 522.916 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' (Loop: ReadInputHeight_ReadInputWidth): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('sX_1_write_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) of variable 'select_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257 on static variable 'sX_1' and 'load' operation ('sX_1_load', firmware/nnet_utils/nnet_pooling_stream.h:191->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) on static variable 'sX_1'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 5.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (4.429ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' consists of the following:\n",
      "\t'icmp' operation ('icmp_ln212', firmware/nnet_utils/nnet_pooling_stream.h:212->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) [156]  (2.47 ns)\n",
      "\tblocking operation 1.96 ns on control path)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.74 seconds; current allocated memory: 523.619 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 524.333 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.7 seconds; current allocated memory: 524.649 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 524.949 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s' consists of the following:\n",
      "\t'phi' operation ('acc_0_V_020', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [51]  (0 ns)\n",
      "\t'mux' operation ('tmp', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [185]  (1.96 ns)\n",
      "\t'add' operation ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [186]  (2.55 ns)\n",
      "\tmultiplexor before 'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [202]  (1.77 ns)\n",
      "\t'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [202]  (0 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 525.506 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.52 seconds; current allocated memory: 526.419 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s' consists of the following:\n",
      "\t'call' operation ('tmp', firmware/nnet_utils/nnet_conv_stream.h:297) to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' [184]  (6.28 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-111]  Elapsed time: 0.68 seconds; current allocated memory: 526.874 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 527.478 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 527.636 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 527.901 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 528.248 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 528.776 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' (Loop: ReadInputHeight_ReadInputWidth): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('sX_write_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) of variable 'select_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257 on static variable 'sX' and 'load' operation ('sX_load', firmware/nnet_utils/nnet_pooling_stream.h:191->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) on static variable 'sX'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 5.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (4.429ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' consists of the following:\n",
      "\t'icmp' operation ('icmp_ln212', firmware/nnet_utils/nnet_pooling_stream.h:212->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) [156]  (2.47 ns)\n",
      "\tblocking operation 1.96 ns on control path)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.86 seconds; current allocated memory: 529.518 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 530.231 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 10.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 29.49 seconds; current allocated memory: 542.252 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 13.29 seconds; current allocated memory: 565.460 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'DataPrepare'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 31.91 seconds; current allocated memory: 576.295 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 12.97 seconds; current allocated memory: 595.908 MB.\n"
     ]
    }
   ],
   "source": [
    "hls_model.build(\n",
    "    csim=False,\n",
    "    synth=True,\n",
    "    cosim=False,\n",
    "    export=False,\n",
    "    vsynth=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc126ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('projects/qat_hls4ml_prj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "361.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
