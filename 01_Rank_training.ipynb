{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2434a683",
   "metadata": {},
   "source": [
    "# PokerML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcefa6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable some console warnings\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af043357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c0167",
   "metadata": {},
   "source": [
    "Make sure that you have Vivado suite in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c375ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44f731",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86514582",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "MODELS_DIR = 'models/'\n",
    "DATA_NPY_DIR = DATA_DIR + '/npy/Rank_npy/'\n",
    "\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLASSES = 13\n",
    "\n",
    "QKERAS_TRAIN = False ## I did not debug yet the issue with the QKeras saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0e75c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240b2617",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = np.load(DATA_NPY_DIR + 'X_train_val.npy')\n",
    "X_test = np.load(DATA_NPY_DIR + 'X_test.npy')\n",
    "y_train_val = np.load(DATA_NPY_DIR + 'y_train_val.npy')\n",
    "y_test = np.load(DATA_NPY_DIR + 'y_test.npy')\n",
    "classes = np.load(DATA_NPY_DIR + 'classes.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ed16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation set: 7987\n",
      "Test set:                 1997\n",
      "Classes:                  13\n"
     ]
    }
   ],
   "source": [
    "print('Train and validation set:', X_train_val.shape[0])\n",
    "print('Test set:                ', X_test.shape[0])\n",
    "print('Classes:                 ', classes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c78db2",
   "metadata": {},
   "source": [
    "## Train QKeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6a2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import Activation\n",
    "from qkeras import QDense, QActivation, QConv2D\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "\n",
    "# # ENABLE THIS IF YOU USE PRUNING\n",
    "# from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "# from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17aee1dd",
   "metadata": {},
   "source": [
    "CHECKPOINT_FILENAME = MODELS_DIR + 'qkeras/model.h5'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv1'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu1'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool1'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "model.add(QDense(NUM_CLASSES,\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 activation='softmax',\n",
    "                 name='output'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bebd4f41",
   "metadata": {},
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "filters_per_conv_layer = [16, 16, 24]\n",
    "neurons_per_dense_layer = [42, 64]\n",
    "\n",
    "x = x_in = Input(shape=input_shape)\n",
    "\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding fused QConv+BN block {} with N={} filters').format(i, f))\n",
    "    x = QConv2DBatchnorm(\n",
    "        int(f),\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        bias_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        use_bias=True,\n",
    "        name='fused_convbn_{}'.format(i),\n",
    "    )(x)\n",
    "    x = QActivation('quantized_relu(6)', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_{}'.format(i))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for i, n in enumerate(neurons_per_dense_layer):\n",
    "    print(('Adding QDense block {} with N={} neurons').format(i, n))\n",
    "    x = QDense(\n",
    "        n,\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        name='dense_%i' % i,\n",
    "        use_bias=False,\n",
    "    )(x)\n",
    "    x = BatchNormalization(name='bn_dense_{}'.format(i))(x)\n",
    "    x = QActivation('quantized_relu(6)', name='dense_act_%i' % i)(x)\n",
    "x = Dense(int(n_classes), name='output_dense')(x)\n",
    "x_out = Activation('softmax', name='output_softmax')(x)\n",
    "qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29dcdfd4",
   "metadata": {},
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "# Define the filters and neurons per layer\n",
    "filters_per_conv_layer = [4, 4]\n",
    "neurons_per_dense_layer = [NUM_CLASSES]\n",
    "\n",
    "# Define input shape\n",
    "x_in = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "# Initialize input tensor\n",
    "x = x_in\n",
    "\n",
    "# Add convolutional layers\n",
    "for i, f in enumerate(filters_per_conv_layer):\n",
    "    print(('Adding QConv2D block {} with N={} filters').format(i, f))\n",
    "    x = QConv2D(\n",
    "        f,\n",
    "        kernel_size=(3, 3),\n",
    "        kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        bias_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=l1(0.0001),\n",
    "        name='conv_%i' % i,\n",
    "    )(x)\n",
    "    x = QActivation('quantized_relu(6)', name='conv_act_%i' % i)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool_%i' % i)(x)\n",
    "\n",
    "# Flatten the output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# # Add dense layers\n",
    "# for i, n in enumerate(neurons_per_dense_layer):\n",
    "#     print(('Adding QDense block {} with N={} neurons').format(i, n))\n",
    "#     x = QDense(\n",
    "#         n,\n",
    "#         kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "#         kernel_initializer='lecun_uniform',\n",
    "#         kernel_regularizer=l1(0.0001),\n",
    "#         name='dense_%i' % i,\n",
    "#         use_bias=False,\n",
    "#     )(x)\n",
    "#     x = BatchNormalization(name='bn_dense_%i' % i)(x)\n",
    "#     x = QActivation('quantized_relu(6)', name='dense_act_%i' % i)(x)\n",
    "\n",
    "# Define output layer\n",
    "x_out = QDense(\n",
    "    NUM_CLASSES,\n",
    "    kernel_quantizer=\"quantized_bits(6,0,alpha=1)\",\n",
    "    kernel_initializer='lecun_uniform',\n",
    "    kernel_regularizer=l1(0.0001),\n",
    "    activation='softmax',\n",
    "    name='output',\n",
    ")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0baa3c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/esp2024/rht2122/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (QConv2D)             (None, 62, 62, 4)         112       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 62, 62, 4)         0         \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling2D)     (None, 31, 31, 4)         0         \n",
      "                                                                 \n",
      " conv2 (QConv2D)             (None, 29, 29, 4)         148       \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 29, 29, 4)         0         \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling2D)     (None, 14, 14, 4)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " output (QDense)             (None, 13)                10205     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,465\n",
      "Trainable params: 10,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_FILENAME = MODELS_DIR + 'qkeras/Ranks_model.h5'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv1'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu1'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool1'))\n",
    "\n",
    "model.add(QConv2D(4,\n",
    "                 kernel_size=(3, 3),\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 name='conv2'))\n",
    "\n",
    "model.add(QActivation(activation=quantized_relu(6),\n",
    "                      name='relu2'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       name='maxpool2'))\n",
    "\n",
    "model.add(Flatten(name='flatten'))\n",
    "\n",
    "# model.add(QDense(32,\n",
    "#                  kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "#                  bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "#                  kernel_initializer='lecun_uniform',\n",
    "#                  kernel_regularizer=l1(0.0001),\n",
    "#                  name='dense1'))\n",
    "\n",
    "# model.add(QActivation(activation=quantized_relu(6),\n",
    "#                       name='relu3'))\n",
    "\n",
    "model.add(QDense(NUM_CLASSES,\n",
    "                 kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
    "                 kernel_initializer='lecun_uniform',\n",
    "                 kernel_regularizer=l1(0.0001),\n",
    "                 activation='softmax',\n",
    "                 name='output'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# # adding pruning \n",
    "# pruning_params = {\n",
    "#     'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "#         initial_sparsity=0.50,\n",
    "#         final_sparsity=0.80,\n",
    "#         begin_step=200,\n",
    "#         end_step=1000)\n",
    "# }\n",
    "# model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19cb8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "if QKERAS_TRAIN:\n",
    "    from qkeras.utils import model_save_quantized_weights\n",
    "\n",
    "    # Using learning rate with exponential decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.001,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    adam = Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    #adam = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "    # A few other callbacks. These should not give warnings on deprecated features.\n",
    "    callbacks = [\n",
    "            ModelCheckpoint(\n",
    "                CHECKPOINT_FILENAME,\n",
    "                monitor='val_loss',\n",
    "                verbose=0,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                save_freq='epoch')\n",
    "       #,\n",
    "       #pruning_callbacks.UpdatePruningStep()\n",
    "       #,#ReduceLROnPlateau(patience=75, min_delta=1**-6), \n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        batch_size=128,\n",
    "        epochs=20,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "# # Strip the model of pruning information\n",
    "#     model = strip_pruning(model)\n",
    "#    model.save(CHECKPOINT_FILENAME)\n",
    "\n",
    "    # Use this instead if you use the callbacks\n",
    "    history_file = CHECKPOINT_FILENAME.replace('.h5', '-history.pkl')\n",
    "    with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    print(f'Saving history to: {history_file}')\n",
    "    print(f'Saved checkpoint to: {CHECKPOINT_FILENAME}')\n",
    "\n",
    "\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model(CHECKPOINT_FILENAME, custom_objects=co, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0644b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "if QKERAS_TRAIN:\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Test')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Test')\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12dd892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 17ms/step\n",
      "QKeras accuracy: 99.599399%\n"
     ]
    }
   ],
   "source": [
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "\n",
    "print(\"QKeras accuracy: {:.6f}%\".format(100.*accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ab571",
   "metadata": {},
   "source": [
    "Pre trained model sul have accuracy = 98.030708%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4935b80",
   "metadata": {},
   "source": [
    "## QKeras to hls4ml (Quantization Aware Training)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3edea044",
   "metadata": {},
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "# Then the QKeras model\n",
    "hls_config_q = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "hls_config_q['Model']['ReuseFactor'] = 512\n",
    "hls_config_q['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_q['LayerName']['output']['Strategy'] = 'Stable'\n",
    "hls_config_q['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config_q['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "plotting.print_dict(hls_config_q)\n",
    "\n",
    "cfg_q = hls4ml.converters.create_config(backend='VivadoAccelerator')\n",
    "cfg_q['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg_q['HLSConfig'] = hls_config_q\n",
    "cfg_q['KerasModel'] = model\n",
    "cfg_q['OutputDir'] = 'projects/qat_hls4ml_prj_rank'\n",
    "# cfg_q['XilinxPart'] = 'xczu5ev-sfvc784-2LV-e'\n",
    "\n",
    "hls_model_q = hls4ml.converters.keras_to_hls(cfg_q)\n",
    "hls_model_q.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5af2572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1_input, layer type: InputLayer, input shapes: [[None, 64, 64, 3]], output shape: [None, 64, 64, 3]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 64, 64, 3]], output shape: [None, 62, 62, 4]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 62, 62, 4]], output shape: [None, 62, 62, 4]\n",
      "Layer name: maxpool1, layer type: MaxPooling2D, input shapes: [[None, 62, 62, 4]], output shape: [None, 31, 31, 4]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 31, 31, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 29, 29, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: maxpool2, layer type: MaxPooling2D, input shapes: [[None, 29, 29, 4]], output shape: [None, 14, 14, 4]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 14, 14, 4]], output shape: [None, 784]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 13]\n",
      "Model\n",
      "  Precision:         ap_fixed<32,16>\n",
      "  ReuseFactor:       256\n",
      "  Strategy:          Resource\n",
      "  BramFactor:        1000000000\n",
      "  TraceOutput:       False\n",
      "LayerName\n",
      "  conv1_input\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  conv1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  conv1_linear\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  relu1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  maxpool1\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  conv2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  conv2_linear\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  relu2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        ufixed<6,0,RND_CONV,SAT>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  maxpool2\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  flatten\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  output\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "      weight:        fixed<6,1>\n",
      "      bias:          fixed<6,1>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "  output_softmax\n",
      "    Trace:           True\n",
      "    Precision\n",
      "      result:        fixed<16,6>\n",
      "    Strategy:        Resource\n",
      "    ReuseFactor:     784\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv1_input, layer type: InputLayer, input shapes: [[None, 64, 64, 3]], output shape: [None, 64, 64, 3]\n",
      "Layer name: conv1, layer type: QConv2D, input shapes: [[None, 64, 64, 3]], output shape: [None, 62, 62, 4]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 62, 62, 4]], output shape: [None, 62, 62, 4]\n",
      "Layer name: maxpool1, layer type: MaxPooling2D, input shapes: [[None, 62, 62, 4]], output shape: [None, 31, 31, 4]\n",
      "Layer name: conv2, layer type: QConv2D, input shapes: [[None, 31, 31, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 29, 29, 4]], output shape: [None, 29, 29, 4]\n",
      "Layer name: maxpool2, layer type: MaxPooling2D, input shapes: [[None, 29, 29, 4]], output shape: [None, 14, 14, 4]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 14, 14, 4]], output shape: [None, 784]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 784]], output shape: [None, 13]\n",
      "Creating HLS model\n",
      "WARNING: Strategy for layer conv1_input set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv1_linear set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer relu1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer maxpool1 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer conv2_linear set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer relu2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer maxpool2 set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer flatten set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer output set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Strategy for layer output_softmax set to \"Resource\", while pipeline style set to \"pipeline\".\n",
      "WARNING: Changing pipeline style to \"dataflow\".\n",
      "WARNING: Invalid ReuseFactor=784 in layer \"conv1\".Using ReuseFactor=108 instead. Valid ReuseFactor(s): 1,3,9,27,54,108.\n",
      "WARNING: Invalid ReuseFactor=784 in layer \"conv2\".Using ReuseFactor=144 instead. Valid ReuseFactor(s): 1,2,3,4,6,9,12,18,36,72,144.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esp2024/rht2122/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "# First, the baseline model\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<32,16>'\n",
    "hls_config['Model']['ReuseFactor'] = 256\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "\n",
    "# Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource'\n",
    "# or increase the reuse factor individually for large layers.\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 784\n",
    "    hls_config['LayerName'][Layer]['Trace'] = True\n",
    "\n",
    "# hls_config['LayerName']['output']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config)\n",
    "\n",
    "cfg = hls4ml.converters.create_config(backend='VivadoAccelerator')\n",
    "cfg['IOType'] = 'io_stream'  # Must set this if using CNNs!\n",
    "cfg['HLSConfig'] = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = 'projects/qat_hls4ml_prj_Rank'\n",
    "#cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69780387",
   "metadata": {},
   "source": [
    "# DISABLE THIS CELL\n",
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['LayerName']['output']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['output']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "config['Model']['ReuseFactor'] = 256\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, output_dir='projects/qat_hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3a957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You set a Part that does not correspond to the Board you specified. The correct Part is now set.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade5610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1997, 64, 64, 3)\n",
      "(10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# IF PREDICTION TAKE TOO MUCH PLEASE\n",
    "# REDUCE THE NUMBER OF INPUTS\n",
    "print(X_test.shape)\n",
    "print(X_test[:10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b8aac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8602e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy quantized: 0.995994%\n",
      "Accuracy hls4ml:    0.995994%\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#print(\"Accuracy baseline:  {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print(\"Accuracy quantized: {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
    "print(\"Accuracy hls4ml:    {:.6f}%\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2f77a",
   "metadata": {},
   "source": [
    "```\n",
    "With pretrained model you should expect:\n",
    "Accuracy quantized: 0.980307%\n",
    "Accuracy hls4ml:    0.979973%\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9936d809",
   "metadata": {},
   "source": [
    "# THIS AND THE FOLLOWING CELL CAN BE USED TO TUNE THE BITWIDTH OF THE LAYERS\n",
    "# THEY TAKE A LOT OF TIME TO RUN SO FOR THE TIME BEING I DISABLE THEM\n",
    "# IF YOU WANT TO MAKE accuracy hls4 == accuracy qkeras WE WILL USE IT\n",
    "_, hls_trace = hls_model.trace(np.ascontiguousarray(X_test)) \n",
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test) \n",
    "\n",
    "print(f'HLS Keys: {hls_trace.keys()}')\n",
    "print(f'Keras Keys: {keras_trace.keys()}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5360660",
   "metadata": {},
   "source": [
    "layers = ['conv1', 'relu1', 'maxpool1', 'conv2', 'relu2', 'maxpool2', 'dense1', 'relu3', 'output_softmax']\n",
    "\n",
    "for idx, layer in enumerate(layers):\n",
    "    keras_layer, hls_layer = keras_trace[layer], hls_trace[layer]\n",
    "    try:\n",
    "        diff = np.average(np.abs(keras_layer - hls_layer ))\n",
    "        print(f'{layer}', '\\t\\t', diff)\n",
    "        \n",
    "        plt.figure(figsize=(7, 5))\n",
    "\n",
    "        plt.scatter(hls_layer.flatten(), keras_layer.flatten())\n",
    "        min_x = min(keras_layer.min(), hls_layer.min())\n",
    "        max_x = min(keras_layer.max(), hls_layer.max())\n",
    "\n",
    "        onnx_min, onnx_max = keras_layer.flatten().min(), keras_layer.flatten().max()\n",
    "        hls_min, hls_max = hls_layer.flatten().min(), hls_layer.flatten().max()\n",
    "        \n",
    "        print(f'hls/keras min: {hls_min}/{onnx_min}')\n",
    "        print(f'hls/keras max: {hls_max}/{onnx_max}')\n",
    "        \n",
    "        plt.plot([min_x, max_x], [min_x, max_x], c='red')\n",
    "        plt.axhline(min_x, c='red')\n",
    "        plt.axhline(max_x, c='red')\n",
    "\n",
    "        plt.title(f'(hls) {layer} -- (keras) {layer}')\n",
    "        plt.xlabel(f'hls4ml - [{hls_min:.3f},  {hls_max:.3f}]')\n",
    "        plt.ylabel(f'keras - [{onnx_min:.3f},  {onnx_max:.3f}]')\n",
    "        plt.yscale('linear')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7717b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using seaborn's heatmap.\n",
    "    \n",
    "    Args:\n",
    "        cm (array, shape = [n, n]): Confusion matrix\n",
    "        class_names (array, shape = [n]): Array of class names\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "y_test_ = np.argmax(y_test, axis=1)\n",
    "y_qkeras_ = np.argmax(y_qkeras, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_, y_qkeras_)\n",
    "\n",
    "plot_confusion_matrix(cm, classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8a152df",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "\n",
    "#hls_model_q.build(csim=False, synth=False, vsynth=True, cosim = False, bitfile = True)\n",
    "hls_model_q.build(csim=False, synth=True, vsynth=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1afdb6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /opt/xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/opt/xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'rht2122' on host 'socp06-ubuntu.c.psyched-span-141520.internal' (Linux_x86_64 version 5.4.0-1106-gcp) on Wed Apr 10 15:26:14 UTC 2024\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Rank'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Rank/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_axi.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/esp2024/rht2122/PokerML/PokerML/projects/qat_hls4ml_prj_Rank/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with an uncertainty of 0.625ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xc7z020-clg400-1'\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -target' configuration: config_export -vivado_optimization_level=2\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -target' configuration: config_compile -name_max_length=20\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 20.\n",
      "INFO: [HLS 200-435] Setting 'config_sdx -target' configuration: set_clock_uncertainty default\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "INFO: [XFORM 203-1172] Optimizing floating point zeros and discarding its signedness.\n",
      "INFO: [XFORM 203-1172] Optimizing floating point zeros and discarding its signedness.\n",
      "INFO: [XFORM 203-1173] Reordering floating point operations aggressively.\n",
      "INFO: [XFORM 203-1176] Optimizing floating point comparison without checking NaN.\n",
      "INFO: [XFORM 203-102] Do not partition external global variables.\n",
      "INFO: [XFORM 203-102] Do not partition I/O variables.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-102] Enabled automatic array partitioning for throughput optimization.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 80.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:37:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:37:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:49:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:49:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:62:71\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject.cpp:62:76\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 6 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_axi.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:17:2\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_axi.cpp:29:5\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 2 issue(s) in file firmware/myproject_axi.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:54 ; elapsed = 00:00:58 . Memory (MB): peak = 965.348 ; gain = 532.145 ; free physical = 14792 ; free virtual = 34073\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:54 ; elapsed = 00:00:58 . Memory (MB): peak = 965.348 ; gain = 532.145 ; free physical = 14792 ; free virtual = 34073\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'void nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:136) in function 'void nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'void nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:136) in function 'void nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>(FORWARD_REFERENCE*, FORWARD_REFERENCE*, FORWARD_REFERENCE::weight_t*, FORWARD_REFERENCE::bias_t*)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[].1' into 'myproject_axi' (firmware/myproject_axi.cpp:21).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:56).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:158->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:305).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:305).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:44).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:51).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:51).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:54).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:54).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[].1' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:52).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, config5>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:204).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:247).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config5>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:188->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:237).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_gt_nin_rem0<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:158->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' into 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:252).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, config9>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:204).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:247).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::shift_line_buffer<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, config9>' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:188->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::Op_max<ap_fixed<32, 16, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_common.h:43->firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_pooling_stream.h:21->firmware/nnet_utils/nnet_pooling_stream.h:204->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:79->firmware/nnet_utils/nnet_dense_resource.h:253).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:21).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:33).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:244).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>::operator[]' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:203).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:60).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:05 ; elapsed = 00:01:09 . Memory (MB): peak = 967.633 ; gain = 534.430 ; free physical = 14712 ; free virtual = 33993\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 1, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 1, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:224) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:235) automatically.\n",
      "WARNING: [SYNCHK 200-23] firmware/myproject_axi.cpp:33: variable-indexed range selection may cause suboptimal QoR.\n",
      "INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:07 ; elapsed = 00:01:12 . Memory (MB): peak = 967.633 ; gain = 534.430 ; free physical = 14686 ; free virtual = 33968\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'data.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:1) on argument 'conv1_input.V.data.V' (firmware/myproject.cpp:7). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:12:98) on argument 'layer12_out.V.data.V' (firmware/myproject.cpp:8). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'out.data' (firmware/myproject_axi.cpp:3).\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'in.data' (firmware/myproject_axi.cpp:3).\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_pack.data.V' (firmware/nnet_utils/nnet_activation_stream.h:237) into a 208-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:45) into a 24-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:45) into a 24-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:184) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:184) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:55) into a 208-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'ctype.data.V' (firmware/myproject_axi.cpp:18) into a 48-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:282) into a 64-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:282) into a 64-bit variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:195) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:195) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:193:47).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:41) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:41) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:243) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:243) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'DataPrepare' (firmware/nnet_utils/nnet_dense_stream.h:36) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:194:62).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:194:62).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) because its parent loop or function is pipelined.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxArrayPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:201) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/nnet_activation_stream.h:213) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-3' (firmware/nnet_utils/nnet_activation_stream.h:222) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxInvPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:241) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:49) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:49) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:198) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' completely with a factor of 4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:193) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:198) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:42) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:58) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:37) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:52) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:77) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 13.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:303) in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:108) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:156) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:303) in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:108) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:156) in function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:233) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:241) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:244) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:194) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:197) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:210) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:213) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-102] Partitioning array 'd_xi_xmax.V' (firmware/nnet_utils/nnet_activation_stream.h:212) automatically.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w6.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w2.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w6.V' : incorrect reshape factor 1.\n",
      "WARNING: [XFORM 203-135] Cannot reshape array 'w2.V' : incorrect reshape factor 1.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w11.V'  in dimension 1 with a block factor of 13.\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.3' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.2' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.1' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer11_out.V.data.V' (firmware/myproject.cpp:60) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'out_local.V.data.V' (firmware/myproject_axi.cpp:12) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer6_out.V.data.V' (firmware/myproject.cpp:47) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer8_out.V.data.V' (firmware/myproject.cpp:51) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer2_out.V.data.V' (firmware/myproject.cpp:35) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer4_out.V.data.V' (firmware/myproject.cpp:39) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer9_out.V.data.V' (firmware/myproject.cpp:55) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer5_out.V.data.V' (firmware/myproject.cpp:43) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'in_local.V.data.V' (firmware/myproject_axi.cpp:11) .\n",
      "INFO: [XFORM 203-101] Partitioning array 'data_array.V' (firmware/nnet_utils/nnet_activation_stream.h:193) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'exp_res.V' (firmware/nnet_utils/nnet_activation_stream.h:219) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.3'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.2'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_stream.h:44:39), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b11.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:33) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.1'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.V' (firmware/nnet_utils/nnet_conv_stream.h:279) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b6.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:104) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.V' (firmware/nnet_utils/nnet_conv_stream.h:279) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:104) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer11_out.V.data.V' (firmware/myproject.cpp:60) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'out_local.V.data.V' (firmware/myproject_axi.cpp:12) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V.data.V' (firmware/myproject.cpp:47) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer8_out.V.data.V' (firmware/myproject.cpp:51) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer2_out.V.data.V' (firmware/myproject.cpp:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer4_out.V.data.V' (firmware/myproject.cpp:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer9_out.V.data.V' (firmware/myproject.cpp:55) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer5_out.V.data.V' (firmware/myproject.cpp:43) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'in_local.V.data.V' (firmware/myproject_axi.cpp:11) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:229) in dimension 2 completely.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:29) accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_resource.h:56:17), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "WARNING: [XFORM 203-104] Completely partitioning array 'kernel_data.V.1'  accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_resource.h:139:17), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 2, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 1, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 8, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::operator()' into 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:43) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 1, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13, nnet::Op_max<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:209) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:224) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config12>' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:235) automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-721] Changing loop 'Loop_1_proc' (firmware/myproject_axi.cpp:17) to a process function for dataflow in function 'myproject_axi'.\n",
      "INFO: [XFORM 203-721] Changing loop 'Loop_2_proc' (firmware/myproject_axi.cpp:31) to a process function for dataflow in function 'myproject_axi'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject', detected/extracted 8 process function(s): \n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'\n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'\n",
      "\t 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>'\n",
      "\t 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject_axi', detected/extracted 4 process function(s): \n",
      "\t 'Loop_1_proc346'\n",
      "\t 'myproject'\n",
      "\t 'Block_myproject_axi_.exit54_proc'\n",
      "\t 'Loop_2_proc'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_activation_stream.h:248:1) in function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>'... converting 53 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:41:61) to (firmware/nnet_utils/nnet_activation_stream.h:41:55) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>'... converting 13 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:41:61) to (firmware/nnet_utils/nnet_activation_stream.h:41:55) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>'... converting 13 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:45:44) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 9 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:45:44) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:43:16) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:45:44) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 9 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:32:90) to (firmware/myproject_axi.cpp:31:49) in function 'Loop_2_proc'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:22:25) to (firmware/myproject_axi.cpp:20:41) in function 'Loop_1_proc346'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.27i16P.i5' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-603] Inlining function 'aesl_mux_load.36i16P.i6' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255).\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:45->firmware/nnet_utils/nnet_common.h:45) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 13, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:232) automatically.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)...3 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:55 ; elapsed = 00:02:00 . Memory (MB): peak = 1093.348 ; gain = 660.145 ; free physical = 14574 ; free virtual = 33856\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:241:66) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:241:66) in function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:79:66) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:79:66) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>'.\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax_stable<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' to 'softmax_stable<array,array<ap_fixed<16,6,5,3,0>,13u>,softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:45:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, softmax_config12>' to 'softmax<array,array<ap_fixed<16,6,5,3,0>,13u>,softmax_config12>' (firmware/nnet_utils/nnet_activation_stream.h:362:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:226:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' to 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:226:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config8>' to 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:41:55)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, relu_config4>' to 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:41:55)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' to 'reduce<ap_fixed<18, 8, 0, 0, 0>, 5, Op_add<ap_fixed<18, 8, 0, 0, 0> > >' (firmware/nnet_utils/nnet_common.h:43:44)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' to 'reduce<ap_fixed<18, 8, 0, 0, 0>, 4, Op_add<ap_fixed<18, 8, 0, 0, 0> > >' (firmware/nnet_utils/nnet_common.h:36:44)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config9>' to 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config9>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_ufixed<6, 0, (ap_q_mode)4, (ap_o_mode)0, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config5>' to 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config5>' (firmware/nnet_utils/nnet_pooling_stream.h:65:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' to 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:13)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_resource.h:1:17)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_resource.h:1:17)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 13u>, config11>' to 'dense<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,13u>,config11>' (firmware/nnet_utils/nnet_dense_stream.h:36:39)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'conv_2d_cl<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:79:27)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' to 'conv_2d_cl<array<ap_fixed,3u>,array<ap_fixed<16,6,5,3,0>,4u>,config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:79:27)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config6>' to 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config6>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 4u>, config2>' to 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config2>' (firmware/nnet_utils/nnet_conv_stream.h:286:5)\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:43) in function 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:129) in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:129) in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>'.\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:02:28 ; elapsed = 00:02:32 . Memory (MB): peak = 1349.348 ; gain = 916.145 ; free physical = 14369 ; free virtual = 33651\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject_axi' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' to 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config2>' to 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array<ap_fixed,3u>,array<ap_fixed<16,6,5,3,0>,4u>,config2>' to 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config4>' to 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config5>' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' to 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'compute_output_buffer_2d<array,array<ap_fixed<16,6,5,3,0>,4u>,config6>' to 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config6>' to 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array<ap_fixed,4u>,array<ap_ufixed<6,0,4,0,0>,4u>,relu_config8>' to 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array<ap_ufixed,4u>,array<ap_fixed<16,6,5,3,0>,4u>,config9>' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config11>' to 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array<ap_fixed,4u>,array<ap_fixed<16,6,5,3,0>,13u>,config11>' to 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'reduce<ap_fixed<18, 8, 0, 0, 0>, 4, Op_add<ap_fixed<18, 8, 0, 0, 0> > >' to 'reduce_ap_fixed_18_8_0_0_0_4_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'reduce<ap_fixed<18, 8, 0, 0, 0>, 5, Op_add<ap_fixed<18, 8, 0, 0, 0> > >' to 'reduce_ap_fixed_18_8_0_0_0_5_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax_stable<array,array<ap_fixed<16,6,5,3,0>,13u>,softmax_config12>' to 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax<array,array<ap_fixed<16,6,5,3,0>,13u>,softmax_config12>' to 'softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'Block_myproject_axi_.exit54_proc' to 'Block_myproject_axi_exit54_proc'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Loop_1_proc346' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 153.45 seconds; current allocated memory: 541.913 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 542.437 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 3u>, config2>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 542.740 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 542.977 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 5.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s' consists of the following:\n",
      "\t'phi' operation ('acc_0_V_020', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [42]  (0 ns)\n",
      "\t'mux' operation ('tmp', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [149]  (1.96 ns)\n",
      "\t'add' operation ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [150]  (2.55 ns)\n",
      "\tmultiplexor before 'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [166]  (1.77 ns)\n",
      "\t'phi' operation ('acc[0].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [166]  (0 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 543.682 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 544.579 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s' consists of the following:\n",
      "\t'call' operation ('tmp', firmware/nnet_utils/nnet_conv_stream.h:297) to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config2_mult>' [147]  (6.28 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 545.004 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 545.519 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 545.630 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 545.902 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 546.270 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 546.799 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' (Loop: ReadInputHeight_ReadInputWidth): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('sX_1_write_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) of variable 'select_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257 on static variable 'sX_1' and 'load' operation ('sX_1_load', firmware/nnet_utils/nnet_pooling_stream.h:191->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) on static variable 'sX_1'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 5.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (4.429ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' consists of the following:\n",
      "\t'icmp' operation ('icmp_ln212', firmware/nnet_utils/nnet_pooling_stream.h:212->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) [156]  (2.47 ns)\n",
      "\tblocking operation 1.96 ns on control path)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 547.485 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 548.163 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed<16, 6, 5, 3, 0>, 4u>, config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 548.523 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 548.822 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s' consists of the following:\n",
      "\t'phi' operation ('acc_0_V_020', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [51]  (0 ns)\n",
      "\t'mux' operation ('tmp', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [185]  (1.96 ns)\n",
      "\t'add' operation ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [186]  (2.55 ns)\n",
      "\tmultiplexor before 'phi' operation ('acc[3].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [195]  (1.77 ns)\n",
      "\t'phi' operation ('acc[3].V') with incoming values : ('acc[0].V', firmware/nnet_utils/nnet_dense_resource.h:139->firmware/nnet_utils/nnet_dense_resource.h:255) [195]  (0 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 549.346 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 550.261 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "WARNING: [SCHED 204-21] Estimated clock period (6.279ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s' consists of the following:\n",
      "\t'call' operation ('tmp', firmware/nnet_utils/nnet_conv_stream.h:297) to 'dense_resource<ap_fixed<16, 6, 5, 3, 0>, ap_fixed<16, 6, 5, 3, 0>, config6_mult>' [184]  (6.28 ns)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 550.760 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 551.364 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 551.497 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 551.764 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 552.159 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 552.647 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "WARNING: [SCHED 204-68] The II Violation in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' (Loop: ReadInputHeight_ReadInputWidth): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 1)\n",
      "   between 'store' operation ('sX_write_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) of variable 'select_ln227', firmware/nnet_utils/nnet_pooling_stream.h:227->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257 on static variable 'sX' and 'load' operation ('sX_load', firmware/nnet_utils/nnet_pooling_stream.h:191->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) on static variable 'sX'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 5.\n",
      "WARNING: [SCHED 204-21] Estimated clock period (4.429ns) exceeds the target (target clock period: 5ns, clock uncertainty: 0.625ns, effective delay budget: 4.375ns).\n",
      "WARNING: [SCHED 204-21] The critical path in module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' consists of the following:\n",
      "\t'icmp' operation ('icmp_ln212', firmware/nnet_utils/nnet_pooling_stream.h:212->firmware/nnet_utils/nnet_pooling_stream.h:247->firmware/nnet_utils/nnet_pooling_stream.h:257) [156]  (2.47 ns)\n",
      "\tblocking operation 1.96 ns on control path)\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 553.352 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 554.030 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 7.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.58 seconds; current allocated memory: 561.807 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.48 seconds; current allocated memory: 578.163 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'DataPrepare'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 17.17 seconds; current allocated memory: 587.467 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.09 seconds; current allocated memory: 590.738 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'reduce_ap_fixed_18_8_0_0_0_4_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'reduce<ap_fixed<18, 8, 0, 0, 0>, 4, Op_add<ap_fixed<18, 8, 0, 0, 0> > >'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.26 seconds; current allocated memory: 591.090 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 591.427 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'reduce_ap_fixed_18_8_0_0_0_5_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'reduce<ap_fixed<18, 8, 0, 0, 0>, 5, Op_add<ap_fixed<18, 8, 0, 0, 0> > >'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 13, Final II = 3, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 591.657 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 591.836 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'softmax_stable<array,array<ap_fixed<16,6,5,3,0>,13u>,softmax_config12>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 13, Final II = 13, Depth = 44.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.76 seconds; current allocated memory: 593.477 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.34 seconds; current allocated memory: 595.414 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.39 seconds; current allocated memory: 595.867 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 596.559 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 597.170 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.27 seconds; current allocated memory: 599.266 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Block_myproject_axi_exit54_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.06 seconds; current allocated memory: 599.932 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 600.151 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Loop_2_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 600.384 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 600.811 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 601.040 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.96 seconds; current allocated memory: 602.354 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Loop_1_proc346' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_ashr_54ns_32ns_54_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_fpext_32ns_64_3_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Loop_1_proc346'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.99 seconds; current allocated memory: 603.902 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_0_0' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_bkb' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_1284_0' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_cud' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_0_1' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_dEe' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_1284_1' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_eOg' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_0_2' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_fYi' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_1284_2' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s_line_buffer_Array_V_g8j' due to the length limit 80\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_3u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.64 seconds; current allocated memory: 608.098 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_5s_16s_20_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_42_32_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 609.859 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3287' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_5' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_6' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_7' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_8' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_12' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_13' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_14' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_15' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_0' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1285' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2286' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_9' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_10' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_11' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pX_3' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 614.106 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2d_cl_array_ap_fixed_3u_array_ap_fixed_16_6_5_3_0_4u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 616.595 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 618.008 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'pX_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_5' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_6' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_7' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_12' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_13' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_14' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_15' is power-on initialization.\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_buffer_Array_V_2_0_0' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_bhbi' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_buffer_Array_V_2_0_1' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_bibs' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_buffer_Array_V_2_0_2' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_bjbC' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_buffer_Array_V_2_0_3' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s_line_bkbM' due to the length limit 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_42_32_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.8 seconds; current allocated memory: 621.096 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_0_0' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_lbW' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_1_0' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_mb6' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_0_1' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_ncg' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_1_1' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_ocq' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_0_2' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_pcA' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_1_2' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_qcK' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_0_3' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_rcU' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_1_1_3' to 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s_line_buffer_Array_V_sc4' due to the length limit 80\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.04 seconds; current allocated memory: 627.566 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_mul_6s_16s_21_3_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_42_32_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 629.732 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_5' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_6' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_7' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_8' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_9' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_10' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_11' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_28' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_29' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_30' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_31' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_32' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_33' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_34' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_35' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_0' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_12' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_13' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_14' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_15' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_27' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pX_2' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'compute_output_buffer_2d_array_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1 seconds; current allocated memory: 635.296 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 638.188 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 639.618 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'pX' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_5' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_6' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_7' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_12' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_13' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_14' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_15' is power-on initialization.\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_buffer_Array_V_3_0_0' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_btde' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_buffer_Array_V_3_0_1' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_budo' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_buffer_Array_V_3_0_2' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_bvdy' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_buffer_Array_V_3_0_3' to 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s_line_bwdI' due to the length limit 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_42_32_1_1': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.88 seconds; current allocated memory: 642.731 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s' is 12555 from HDL expression: ((icmp_ln43_reg_30245 == 1'd0) & (1'b0 == ap_block_pp0_stage0_11001) & (ap_enable_reg_pp0_iter1 == 1'b1) & (1'b1 == ap_CS_fsm_pp0_stage0))\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_5s_16s_21_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_mul_6s_16s_22_3_1': 12 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_78410_16_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.83 seconds; current allocated memory: 662.525 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 11 seconds; current allocated memory: 728.607 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'reduce_ap_fixed_18_8_0_0_0_4_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_134_18_1_0': 4 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'reduce_ap_fixed_18_8_0_0_0_4_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.67 seconds; current allocated memory: 772.413 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'reduce_ap_fixed_18_8_0_0_0_5_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'reduce_ap_fixed_18_8_0_0_0_5_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.65 seconds; current allocated memory: 774.266 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_exp_table1' to 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_exp_tabxdS' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_invert_table2' to 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_invert_yd2' due to the length limit 80\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_17ns_18s_26_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.67 seconds; current allocated memory: 778.290 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.31 seconds; current allocated memory: 785.937 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config5_U0' to 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configzec' due to the length limit 80\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_config9_U0' to 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configAem' due to the length limit 80\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.01 seconds; current allocated memory: 789.051 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Block_myproject_axi_exit54_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Block_myproject_axi_exit54_proc'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.76 seconds; current allocated memory: 792.027 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Loop_2_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_lshr_32ns_32ns_32_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mux_134_16_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_shl_64ns_32ns_64_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Loop_2_proc'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 793.495 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/in_data' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/in_last_V' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/out_data' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/out_last_V' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject_axi' to 'ap_ctrl_none'.\n",
      "WARNING: [RTGEN 206-101] RTL name 'fifo_w16_d1_A' is changed to 'fifo_w16_d1_A_x' due to conflict.\n",
      "WARNING: [HLS 200-631] Ignoring ap_ctrl_none interface for myproject_axi due to Block_myproject_axi_.exit54_proc with non-FIFO I/O\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject_axi'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.9 seconds; current allocated memory: 796.260 MB.\n",
      "INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.\n",
      "INFO: [HLS 200-789] **** Estimated Fmax: 159.26 MHz\n",
      "INFO: [RTMG 210-286] Generating pipelined shifter : 'myproject_axi_ashr_54ns_32ns_54_2_1'\n",
      "INFO: [RTMG 210-282] Generating pipelined core: 'myproject_axi_mul_5s_16s_20_2_1_MulnS_0'\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s_outidx3_rom' using distributed ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config2_mult_s_w2_V_rom' using distributed ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s_outidx_rom' using distributed ROMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTMG 210-279] Implementing memory 'dense_resource_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config6_mult_s_w6_V_rom' using distributed ROMs.\n",
      "INFO: [RTMG 210-288] Generating pipelined multiplexer : 'myproject_axi_mux_78410_16_2_1'\n",
      "INFO: [RTMG 210-282] Generating pipelined core: 'myproject_axi_mul_5s_16s_21_2_1_MulnS_1'\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_wrapper_ap_fixed_16_6_5_3_0_ap_fixed_16_6_5_3_0_config11_s_w11_V_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-282] Generating pipelined core: 'myproject_axi_mul_17ns_18s_26_2_1_MulnS_2'\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_exp_tabxdS_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_stable_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_s_invert_yd2_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_0_V_U(fifo_w16_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_1_V_U(fifo_w16_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_2_V_U(fifo_w16_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_3_V_U(fifo_w16_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_0_V_U(fifo_w6_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_1_V_U(fifo_w6_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_2_V_U(fifo_w6_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_3_V_U(fifo_w6_d3844_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_0_V_U(fifo_w16_d961_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_1_V_U(fifo_w16_d961_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_2_V_U(fifo_w16_d961_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_3_V_U(fifo_w16_d961_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_0_V_U(fifo_w16_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_1_V_U(fifo_w16_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_2_V_U(fifo_w16_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_3_V_U(fifo_w16_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_0_V_U(fifo_w6_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_1_V_U(fifo_w6_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_2_V_U(fifo_w6_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_3_V_U(fifo_w6_d841_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_0_V_U(fifo_w16_d196_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_1_V_U(fifo_w16_d196_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_2_V_U(fifo_w16_d196_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_3_V_U(fifo_w16_d196_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_U0_U(start_for_relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config4_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configzec_U(start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configzec)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_U0_U(start_for_conv_2d_cl_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_4u_config6_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_U0_U(start_for_relu_array_ap_fixed_4u_array_ap_ufixed_6_0_4_0_0_4u_relu_config8_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configAem_U(start_for_pooling2d_cl_array_ap_ufixed_4u_array_ap_fixed_16_6_5_3_0_4u_configAem)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_U0_U(start_for_dense_array_ap_fixed_4u_array_ap_fixed_16_6_5_3_0_13u_config11_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_U0_U(start_for_softmax_array_array_ap_fixed_16_6_5_3_0_13u_softmax_config12_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-286] Generating pipelined shifter : 'myproject_axi_lshr_32ns_32ns_32_2_1'\n",
      "INFO: [RTMG 210-286] Generating pipelined shifter : 'myproject_axi_shl_64ns_32ns_64_2_1'\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_0_V_U(fifo_w16_d4096_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_1_V_U(fifo_w16_d4096_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_2_V_U(fifo_w16_d4096_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'is_last_0_i_loc_channel_U(fifo_w1_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_0_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_1_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_2_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_3_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_4_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_5_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_6_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_727_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_8_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_9_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_10_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_11_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_12_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_myproject_U0_U(start_for_myproject_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_Block_myproject_axi_exit54_proc_U0_U(start_for_Block_myproject_axi_exit54_proc_U0)' using Shift Registers.\n",
      "INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:04:16 ; elapsed = 00:04:32 . Memory (MB): peak = 1621.352 ; gain = 1188.148 ; free physical = 14068 ; free virtual = 33369\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject_axi.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject_axi.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h4m28s *****\n",
      "INFO: [HLS 200-112] Total elapsed time: 272.46 seconds; peak allocated memory: 796.260 MB.\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Wed Apr 10 15:30:46 2024...\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n",
      "Vivado synthesis report not found.\n",
      "Cosim report not found.\n",
      "Timing report not found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CSynthesisReport': {'TargetClockPeriod': '5.00',\n",
       "  'EstimatedClockPeriod': '6.279',\n",
       "  'BestLatency': '484027',\n",
       "  'WorstLatency': '484028',\n",
       "  'IntervalMin': '118786',\n",
       "  'IntervalMax': '483330',\n",
       "  'BRAM_18K': '59',\n",
       "  'DSP': '16',\n",
       "  'FF': '50659',\n",
       "  'LUT': '38614',\n",
       "  'URAM': '0',\n",
       "  'AvailableBRAM_18K': '280',\n",
       "  'AvailableDSP': '220',\n",
       "  'AvailableFF': '106400',\n",
       "  'AvailableLUT': '53200',\n",
       "  'AvailableURAM': '0'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(\n",
    "    csim=False,\n",
    "    synth=True,\n",
    "    cosim=False,\n",
    "    export=False,\n",
    "    vsynth=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cc126ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 solution(s) in projects/qat_hls4ml_prj/myproject_prj.\n",
      "Reports for solution \"solution1\":\n",
      "\n",
      "C simulation report not found.\n",
      "Synthesis report not found.\n",
      "Co-simulation report not found.\n"
     ]
    }
   ],
   "source": [
    "hls4ml.report.read_vivado_report('projects/qat_hls4ml_prj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "361.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
